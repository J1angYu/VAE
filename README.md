# VAE (Variational Autoencoder) å®ç°

ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„å˜åˆ†è‡ªç¼–ç å™¨(VAE)å®ç°ï¼Œæ”¯æŒå¤šç§æ¨¡å‹æ¶æ„ã€æŸå¤±å‡½æ•°å’Œè®­ç»ƒç­–ç•¥ã€‚

## é¡¹ç›®ç‰¹æ€§

### ğŸ—ï¸ æ¨¡å‹æ¶æ„
- **MLP VAE**: åŸºäºå…¨è¿æ¥å±‚çš„ç»å…¸VAEå®ç°
- **CNN VAE**: åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„VAEï¼Œé€‚ç”¨äºå›¾åƒæ•°æ®
- **Progressive VAE**: æ¸è¿›å¼è®­ç»ƒçš„VAEï¼Œæ”¯æŒå¤šåˆ†è¾¨ç‡è®­ç»ƒ
- **Residual Progressive VAE**: æ®‹å·®æ¸è¿›å¼VAE

### ğŸ“Š æ•°æ®é›†æ”¯æŒ
- **MNIST**: æ‰‹å†™æ•°å­—æ•°æ®é›†
- **FreyFaces**: äººè„¸æ•°æ®é›† (28x20 ç°åº¦å›¾åƒ)

### ğŸ”§ æŸå¤±å‡½æ•°
- **é‡å»ºæŸå¤±**:
  - Binary Cross Entropy (BCE)
  - Gaussian Negative Log-Likelihood
- **KLæ•£åº¦**:
  - è§£æå½¢å¼ (Analytic)
  - è’™ç‰¹å¡æ´›é‡‡æ · (Monte Carlo)

### ğŸ“ˆ å®éªŒç®¡ç†
- è‡ªåŠ¨å®éªŒç›®å½•åˆ›å»ºå’Œé…ç½®ä¿å­˜
- è®­ç»ƒæ—¥å¿—è®°å½•
- æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜
- å¯è§†åŒ–ç»“æœç”Ÿæˆ (é‡å»ºå›¾åƒã€ç”Ÿæˆæ ·æœ¬)
- FIDè¯„ä¼°æŒ‡æ ‡

## å®‰è£…ä¾èµ–

```bash
pip install torch torchvision scipy numpy matplotlib
```

## å¿«é€Ÿå¼€å§‹

### 1. è®­ç»ƒæ ‡å‡†VAE

```bash
# MNISTæ•°æ®é›† + MLPæ¨¡å‹ + BCEé‡å»ºæŸå¤±
python train_vae.py --dataset mnist --model mlp --recon bce --epochs 30

# FreyFacesæ•°æ®é›† + MLPæ¨¡å‹ + Gaussiané‡å»ºæŸå¤±
python train_vae.py --dataset freyfaces --model mlp --recon gaussian --epochs 20

# MNISTæ•°æ®é›† + CNNæ¨¡å‹
python train_vae.py --dataset mnist --model cnn --recon bce --epochs 30
```

### 2. è®­ç»ƒProgressive VAE

```bash
# Progressive VAEè®­ç»ƒ
python train_provae.py --epochs_per_stage 10 --start_res 4 --final_res 32
```

## å‘½ä»¤è¡Œå‚æ•°

### train_vae.py å‚æ•°

#### åŸºæœ¬å‚æ•°
- `--exp_name`: å®éªŒåç§° (é»˜è®¤: 'vae')
- `--data_path`: æ•°æ®è·¯å¾„ (é»˜è®¤: './data')
- `--dataset`: æ•°æ®é›†é€‰æ‹© ['mnist', 'freyfaces']
- `--model`: æ¨¡å‹ç±»å‹ ['mlp', 'cnn']

#### æ¨¡å‹å‚æ•°
- `--input_dim`: è¾“å…¥ç»´åº¦ (ä»…MLPï¼Œé»˜è®¤è‡ªåŠ¨è®¾ç½®)
- `--hidden_dim`: éšè—å±‚ç»´åº¦ (é»˜è®¤: 400)
- `--z_dim`: æ½œåœ¨ç©ºé—´ç»´åº¦ (é»˜è®¤: 20)

#### è®­ç»ƒå‚æ•°
- `--batch_size`: æ‰¹æ¬¡å¤§å° (é»˜è®¤: 128)
- `--lr`: å­¦ä¹ ç‡ (é»˜è®¤: 1e-3)
- `--epochs`: è®­ç»ƒè½®æ•° (é»˜è®¤: 30)
- `--seed`: éšæœºç§å­ (é»˜è®¤: 42)

#### æŸå¤±å‡½æ•°å‚æ•°
- `--recon`: é‡å»ºæŸå¤±ç±»å‹ ['bce', 'gaussian']
- `--kl`: KLæ•£åº¦è®¡ç®—æ–¹å¼ ['analytic', 'mc']
- `--beta`: KLæ•£åº¦æƒé‡ (é»˜è®¤: 1.0)
- `--reduction`: æŸå¤±èšåˆæ–¹å¼ ['sum', 'mean']
- `--sigma`: Gaussiané‡å»ºæŸå¤±çš„æ ‡å‡†å·® (é»˜è®¤: 1.0)
- `--sigma_learnable`: ä½¿sigmaå‚æ•°å¯å­¦ä¹ 
- `--include_const`: Gaussian NLLåŒ…å«å¸¸æ•°é¡¹

### train_provae.py å‚æ•°

- `--epochs_per_stage`: æ¯é˜¶æ®µè®­ç»ƒè½®æ•° (é»˜è®¤: 10)
- `--fadein_ratio`: æ¸å…¥æ¯”ä¾‹ (é»˜è®¤: 0.5)
- `--start_res`: èµ·å§‹åˆ†è¾¨ç‡ (é»˜è®¤: 4)
- `--final_res`: æœ€ç»ˆåˆ†è¾¨ç‡ (é»˜è®¤: 32)
- `--base_ch`: åŸºç¡€é€šé“æ•° (é»˜è®¤: 128)
- `--min_ch`: æœ€å°é€šé“æ•° (é»˜è®¤: 16)

## é¡¹ç›®ç»“æ„
VAE/
â”œâ”€â”€ models/                    # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ VAE.py                # æ ‡å‡†MLP VAE
â”‚   â”œâ”€â”€ CNN_VAE.py            # å·ç§¯VAE
â”‚   â”œâ”€â”€ ProVAE.py             # æ¸è¿›å¼VAE
â”‚   â””â”€â”€ ResProVAE.py          # æ®‹å·®æ¸è¿›å¼VAE
â”œâ”€â”€ train_vae.py              # æ ‡å‡†VAEè®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_provae.py           # æ¸è¿›å¼VAEè®­ç»ƒè„šæœ¬
â”œâ”€â”€ loss.py                   # æŸå¤±å‡½æ•°å®ç°
â”œâ”€â”€ utils.py                  # å·¥å…·å‡½æ•°
â”œâ”€â”€ experiments/              # å®éªŒç»“æœç›®å½•
â””â”€â”€ data/                     # æ•°æ®ç›®å½•